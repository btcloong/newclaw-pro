# AI å­¦ä¹ æ¨¡å— - ä»æ¦‚å¿µåˆ°å®æˆ˜

> NewClaw å‡ºå“çš„ AI å­¦ä¹ è·¯çº¿å›¾ï¼Œå¸®åŠ©ä½ ç³»ç»ŸæŒæ¡ AI æ ¸å¿ƒæ¦‚å¿µä¸å®æˆ˜æŠ€èƒ½

---

## ğŸ“š ç¬¬ä¸€éƒ¨åˆ†ï¼šAI æ ¸å¿ƒæ¦‚å¿µä¸çŸ¥è¯†ç‚¹

### ä¸€ã€åŸºç¡€æ¦‚å¿µ

#### 1. æœºå™¨å­¦ä¹  (Machine Learning)
| æ¦‚å¿µ | è¯´æ˜ | å­¦ä¹ èµ„æº |
|------|------|----------|
| **ç›‘ç£å­¦ä¹ ** | ä½¿ç”¨æ ‡æ³¨æ•°æ®è®­ç»ƒæ¨¡å‹ | [Google ML Crash Course](https://developers.google.com/machine-learning/crash-course) |
| **æ— ç›‘ç£å­¦ä¹ ** | ä»æ— æ ‡æ³¨æ•°æ®ä¸­å‘ç°æ¨¡å¼ | [Stanford CS229](https://cs229.stanford.edu/) |
| **å¼ºåŒ–å­¦ä¹ ** | é€šè¿‡å¥–åŠ±æœºåˆ¶å­¦ä¹ å†³ç­– | [Spinning Up in RL](https://spinningup.openai.com/) |
| **è¿ç§»å­¦ä¹ ** | å°†å·²å­¦çŸ¥è¯†åº”ç”¨åˆ°æ–°ä»»åŠ¡ | [Hugging Face Course](https://huggingface.co/course) |

#### 2. æ·±åº¦å­¦ä¹  (Deep Learning)
| æ¦‚å¿µ | è¯´æ˜ | å…³é”®çŸ¥è¯†ç‚¹ |
|------|------|------------|
| **ç¥ç»ç½‘ç»œ** | æ¨¡æ‹Ÿäººè„‘çš„ç¥ç»å…ƒè¿æ¥ | å‰å‘ä¼ æ’­ã€åå‘ä¼ æ’­ã€æ¢¯åº¦ä¸‹é™ |
| **CNN** | å·ç§¯ç¥ç»ç½‘ç»œï¼Œæ“…é•¿å›¾åƒå¤„ç† | å·ç§¯å±‚ã€æ± åŒ–å±‚ã€ç‰¹å¾æå– |
| **RNN/LSTM** | å¾ªç¯ç¥ç»ç½‘ç»œï¼Œå¤„ç†åºåˆ—æ•°æ® | æ—¶åºå»ºæ¨¡ã€é•¿çŸ­æœŸè®°å¿† |
| **Transformer** | æ³¨æ„åŠ›æœºåˆ¶æ¶æ„ï¼ŒNLPä¸»æµ | Self-Attentionã€å¤šå¤´æ³¨æ„åŠ› |

#### 3. å¤§è¯­è¨€æ¨¡å‹ (LLM)
| æ¦‚å¿µ | è¯´æ˜ | ä»£è¡¨æ¨¡å‹ |
|------|------|----------|
| **GPTæ¶æ„** | ç”Ÿæˆå¼é¢„è®­ç»ƒTransformer | GPT-4, GPT-4.5, Claude, Llama |
| **Tokenization** | æ–‡æœ¬åˆ†è¯å¤„ç† | BPE, WordPiece, SentencePiece |
| **ä¸Šä¸‹æ–‡çª—å£** | æ¨¡å‹èƒ½å¤„ç†çš„æ–‡æœ¬é•¿åº¦ | 4K, 32K, 128K, 2M tokens |
| **æ¶Œç°èƒ½åŠ›** | è§„æ¨¡è¾¾åˆ°ä¸€å®šç¨‹åº¦åå‡ºç°çš„æ–°èƒ½åŠ› | æ¨ç†ã€ä»£ç ç”Ÿæˆã€å¤šæ¨¡æ€ |

#### 4. ç”Ÿæˆå¼ AI (Generative AI)
| æ¦‚å¿µ | è¯´æ˜ | åº”ç”¨åœºæ™¯ |
|------|------|----------|
| **æ–‡æœ¬ç”Ÿæˆ** | ç”Ÿæˆè‡ªç„¶è¯­è¨€æ–‡æœ¬ | å†™ä½œåŠ©æ‰‹ã€ä»£ç ç”Ÿæˆ |
| **å›¾åƒç”Ÿæˆ** | ä»æ–‡æœ¬/å›¾åƒç”Ÿæˆå›¾åƒ | Midjourney, DALL-E, Stable Diffusion |
| **éŸ³é¢‘ç”Ÿæˆ** | è¯­éŸ³åˆæˆã€éŸ³ä¹ç”Ÿæˆ | ElevenLabs, Suno |
| **è§†é¢‘ç”Ÿæˆ** | æ–‡æœ¬/å›¾åƒç”Ÿæˆè§†é¢‘ | Sora, Runway, Pika |
| **å¤šæ¨¡æ€** | å¤„ç†å¤šç§ç±»å‹æ•°æ® | GPT-4V, Gemini, Claude 3 |

---

### äºŒã€è¿›é˜¶æ¦‚å¿µ

#### 5. æ¨¡å‹ä¼˜åŒ–ä¸éƒ¨ç½²
| æ¦‚å¿µ | è¯´æ˜ | å·¥å…·/æ¡†æ¶ |
|------|------|-----------|
| **é‡åŒ– (Quantization)** | é™ä½æ¨¡å‹ç²¾åº¦ä»¥å‡å°‘å¤§å° | GPTQ, AWQ, GGUF |
| **è’¸é¦ (Distillation)** | å¤§æ¨¡å‹çŸ¥è¯†è¿ç§»åˆ°å°æ¨¡å‹ | æ•™å¸ˆ-å­¦ç”Ÿæ¨¡å‹ |
| **å‰ªæ (Pruning)** | ç§»é™¤ä¸é‡è¦çš„æƒé‡ | ç»“æ„åŒ–/éç»“æ„åŒ–å‰ªæ |
| **LoRA/QLoRA** | ä½ç§©é€‚é…ï¼Œé«˜æ•ˆå¾®è°ƒ | PEFTåº“ |
| **æ¨ç†ä¼˜åŒ–** | åŠ é€Ÿæ¨¡å‹æ¨ç† | vLLM, TensorRT, ONNX |

#### 6. AI Agent æ ¸å¿ƒæ¦‚å¿µ
| æ¦‚å¿µ | è¯´æ˜ | å…³é”®æŠ€æœ¯ |
|------|------|----------|
| **Agentæ¶æ„** | æ„ŸçŸ¥-å†³ç­–-æ‰§è¡Œå¾ªç¯ | ReAct, Plan-and-Solve |
| **å·¥å…·ä½¿ç”¨ (Tool Use)** | è°ƒç”¨å¤–éƒ¨APIå’Œå·¥å…· | Function Calling |
| **è®°å¿†ç³»ç»Ÿ** | çŸ­æœŸ/é•¿æœŸè®°å¿†ç®¡ç† | Vector DB, RAG |
| **å¤šAgentåä½œ** | å¤šä¸ªAgentååŒå·¥ä½œ | AutoGen, CrewAI |
| **è‡ªä¸»è§„åˆ’** | åˆ†è§£ä»»åŠ¡å¹¶æ‰§è¡Œ | Chain-of-Thought, Tree-of-Thoughts |

#### 7. RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ)
| æ¦‚å¿µ | è¯´æ˜ | ç»„ä»¶ |
|------|------|------|
| **Embedding** | æ–‡æœ¬å‘é‡åŒ–è¡¨ç¤º | OpenAI, BGE, M3E |
| **å‘é‡æ•°æ®åº“** | å­˜å‚¨å’Œæ£€ç´¢å‘é‡ | Pinecone, Milvus, Chroma |
| **åˆ†å—ç­–ç•¥** | æ–‡æ¡£åˆ‡åˆ†æ–¹æ³• | å›ºå®šé•¿åº¦ã€è¯­ä¹‰åˆ†å— |
| **é‡æ’åº** | ä¼˜åŒ–æ£€ç´¢ç»“æœ | Cross-encoder |

---

### ä¸‰ã€æƒå¨å­¦ä¹ èµ„æº

#### ğŸ“ åœ¨çº¿è¯¾ç¨‹
| è¯¾ç¨‹ | å¹³å° | éš¾åº¦ | é“¾æ¥ |
|------|------|------|------|
| **æœºå™¨å­¦ä¹ ** | å´æ©è¾¾ | å…¥é—¨ | [Coursera](https://www.coursera.org/learn/machine-learning) |
| **æ·±åº¦å­¦ä¹ ä¸“é¡¹** | å´æ©è¾¾ | ä¸­çº§ | [Coursera](https://www.coursera.org/specializations/deep-learning) |
| **Fast.ai** | fast.ai | å®æˆ˜ | [fast.ai](https://www.fast.ai/) |
| **Hugging Face NLP** | HF | ä¸­çº§ | [Course](https://huggingface.co/course) |
| **CS224N** | Stanford | é«˜çº§ | [NLP with DL](https://web.stanford.edu/class/cs224n/) |
| **CS231n** | Stanford | é«˜çº§ | [CNN for CV](https://cs231n.github.io/) |

#### ğŸ“– å¿…è¯»è®ºæ–‡
| è®ºæ–‡ | å¹´ä»½ | é‡è¦æ€§ | é“¾æ¥ |
|------|------|--------|------|
| **Attention Is All You Need** | 2017 | â­â­â­ Transformeræ¶æ„ | [arXiv](https://arxiv.org/abs/1706.03762) |
| **GPT-3** | 2020 | â­â­â­ å¤§æ¨¡å‹é‡Œç¨‹ç¢‘ | [arXiv](https://arxiv.org/abs/2005.14165) |
| **InstructGPT** | 2022 | â­â­â­ RLHFè®­ç»ƒ | [arXiv](https://arxiv.org/abs/2203.02155) |
| **LLaMA** | 2023 | â­â­â­ å¼€æºå¤§æ¨¡å‹ | [arXiv](https://arxiv.org/abs/2302.13971) |
| **RAG** | 2020 | â­â­ æ£€ç´¢å¢å¼º | [arXiv](https://arxiv.org/abs/2005.11401) |
| **ReAct** | 2023 | â­â­â­ Agentæ¶æ„ | [arXiv](https://arxiv.org/abs/2210.03629) |

#### ğŸ› ï¸ å¼€å‘å·¥å…·
| å·¥å…· | ç”¨é€” | é“¾æ¥ |
|------|------|------|
| **PyTorch** | æ·±åº¦å­¦ä¹ æ¡†æ¶ | [pytorch.org](https://pytorch.org/) |
| **TensorFlow** | æ·±åº¦å­¦ä¹ æ¡†æ¶ | [tensorflow.org](https://www.tensorflow.org/) |
| **Transformers** | é¢„è®­ç»ƒæ¨¡å‹åº“ | [Hugging Face](https://huggingface.co/docs/transformers) |
| **LangChain** | LLMåº”ç”¨å¼€å‘ | [langchain.com](https://www.langchain.com/) |
| **LlamaIndex** | RAGå¼€å‘æ¡†æ¶ | [llamaindex.ai](https://www.llamaindex.ai/) |
| **Ollama** | æœ¬åœ°è¿è¡Œå¤§æ¨¡å‹ | [ollama.com](https://ollama.com/) |

---

## ğŸš€ ç¬¬äºŒéƒ¨åˆ†ï¼šAI æ¨¡å‹å®šåˆ¶åŒ–å®æˆ˜

### ä¸€ã€æ¨¡å‹å¾®è°ƒ (Fine-tuning)

#### æ–¹å¼å¯¹æ¯”
| æ–¹å¼ | é€‚ç”¨åœºæ™¯ | æˆæœ¬ | æ•ˆæœ |
|------|----------|------|------|
| **å…¨å‚æ•°å¾®è°ƒ** | å¤§é‡æ•°æ®ã€å……è¶³ç®—åŠ› | é«˜ | æœ€å¥½ |
| **LoRA** | æ¶ˆè´¹çº§GPUã€å¿«é€Ÿè¿­ä»£ | ä½ | å¾ˆå¥½ |
| **QLoRA** | æ˜¾å­˜å—é™ã€å¤§æ¨¡å‹å¾®è°ƒ | å¾ˆä½ | å¥½ |
| **Prompt Tuning** | å¿«é€Ÿå®éªŒã€å°‘æ ·æœ¬ | æä½ | ä¸€èˆ¬ |
| **Adapter** | å¤šä»»åŠ¡ã€æ¨¡å—åŒ– | ä½ | å¥½ |

#### å®æˆ˜ï¼šä½¿ç”¨ LoRA å¾®è°ƒ Llama

```python
# 1. å®‰è£…ä¾èµ–
# pip install transformers peft datasets accelerate

from transformers import (
    AutoModelForCausalLM, 
    AutoTokenizer,
    TrainingArguments,
    Trainer
)
from peft import LoraConfig, get_peft_model, TaskType
from datasets import load_dataset

# 2. åŠ è½½åŸºç¡€æ¨¡å‹
model_name = "meta-llama/Llama-2-7b-hf"  # æˆ– "Qwen/Qwen2.5-7B"
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained(model_name)

# 3. é…ç½® LoRA
lora_config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    r=16,                    # LoRA rank
    lora_alpha=32,           # ç¼©æ”¾å‚æ•°
    lora_dropout=0.05,
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],
    bias="none"
)

# 4. åº”ç”¨ LoRA
model = get_peft_model(model, lora_config)
model.print_trainable_parameters()  # æŸ¥çœ‹å¯è®­ç»ƒå‚æ•°é‡

# 5. å‡†å¤‡æ•°æ®
dataset = load_dataset("json", data_files="your_data.jsonl")

def preprocess(examples):
    texts = [f"### æŒ‡ä»¤:\n{prompt}\n\n### å›å¤:\n{response}"
             for prompt, response in zip(examples["instruction"], examples["output"])]
    return tokenizer(texts, truncation=True, max_length=512, padding="max_length")

tokenized_dataset = dataset.map(preprocess, batched=True)

# 6. è®­ç»ƒ
training_args = TrainingArguments(
    output_dir="./lora_output",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    learning_rate=2e-4,
    fp16=True,
    logging_steps=10,
    save_strategy="epoch"
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset["train"],
)

trainer.train()

# 7. ä¿å­˜æ¨¡å‹
model.save_pretrained("./lora_adapter")
```

#### æ•°æ®æ ¼å¼ç¤ºä¾‹ (JSONL)
```json
{"instruction": "è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ", "input": "", "output": "æœºå™¨å­¦ä¹ æ˜¯..."}
{"instruction": "å°†ä¸­æ–‡ç¿»è¯‘æˆè‹±æ–‡", "input": "ä½ å¥½ä¸–ç•Œ", "output": "Hello World"}
```

---

### äºŒã€æœ¬åœ°éƒ¨ç½²å¤§æ¨¡å‹

#### ä½¿ç”¨ Ollama (æœ€ç®€å•)
```bash
# 1. å®‰è£… Ollama
# macOS/Linux: curl -fsSL https://ollama.com/install.sh | sh

# 2. æ‹‰å–æ¨¡å‹
ollama pull llama3.2
ollama pull qwen2.5
ollama pull deepseek-coder

# 3. è¿è¡Œæ¨¡å‹
ollama run llama3.2

# 4. API è°ƒç”¨
curl http://localhost:11434/api/generate -d '{
  "model": "llama3.2",
  "prompt": "è§£é‡Šä»€ä¹ˆæ˜¯AI Agent"
}'
```

#### ä½¿ç”¨ vLLM (é«˜æ€§èƒ½)
```bash
# å®‰è£…
pip install vllm

# å¯åŠ¨æœåŠ¡
python -m vllm.entrypoints.openai.api_server \
  --model "Qwen/Qwen2.5-7B-Instruct" \
  --tensor-parallel-size 1 \
  --max-model-len 8192

# API è°ƒç”¨ (OpenAI å…¼å®¹)
curl http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "Qwen/Qwen2.5-7B-Instruct",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

---

## ğŸ¤– ç¬¬ä¸‰éƒ¨åˆ†ï¼šAI Agent å¼€å‘å®æˆ˜

### ä¸€ã€Agent æ ¸å¿ƒæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              User Input                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           LLM (å¤§è„‘)                     â”‚
â”‚  - ç†è§£æ„å›¾                              â”‚
â”‚  - è§„åˆ’ä»»åŠ¡                              â”‚
â”‚  - ç”Ÿæˆè¡ŒåŠ¨                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Tool Use (å·¥å…·è°ƒç”¨)              â”‚
â”‚  - æœç´¢å¼•æ“                              â”‚
â”‚  - ä»£ç æ‰§è¡Œ                              â”‚
â”‚  - APIè°ƒç”¨                               â”‚
â”‚  - æ•°æ®åº“æŸ¥è¯¢                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Memory (è®°å¿†ç³»ç»Ÿ)                â”‚
â”‚  - çŸ­æœŸè®°å¿†ï¼šå½“å‰å¯¹è¯                     â”‚
â”‚  - é•¿æœŸè®°å¿†ï¼šå‘é‡æ•°æ®åº“                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### äºŒã€ä½¿ç”¨ LangChain å¼€å‘ Agent

#### 1. åŸºç¡€ Agent
```python
# pip install langchain langchain-openai

from langchain import OpenAI, LLMMathChain, SerpAPIWrapper
from langchain.agents import initialize_agent, Tool, AgentType
from langchain.memory import ConversationBufferMemory

# å®šä¹‰å·¥å…·
search = SerpAPIWrapper()
llm_math = LLMMathChain(llm=OpenAI())

tools = [
    Tool(
        name="Search",
        func=search.run,
        description="ç”¨äºæœç´¢å®æ—¶ä¿¡æ¯"
    ),
    Tool(
        name="Calculator",
        func=llm_math.run,
        description="ç”¨äºæ•°å­¦è®¡ç®—"
    )
]

# åˆå§‹åŒ– Agent
memory = ConversationBufferMemory(memory_key="chat_history")
llm = OpenAI(temperature=0)

agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
    memory=memory,
    verbose=True
)

# è¿è¡Œ
response = agent.run("ä»Šå¤©åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿç„¶åè®¡ç®—25çš„å¹³æ–¹")
```

#### 2. ReAct Agent (æ¨ç†+è¡ŒåŠ¨)
```python
from langchain.agents import create_react_agent, AgentExecutor
from langchain import hub
from langchain.tools import Tool
from langchain_openai import ChatOpenAI

# è·å– ReAct prompt
prompt = hub.pull("hwchase17/react")

# å®šä¹‰å·¥å…·
def search_web(query: str) -> str:
    """æœç´¢ç½‘ç»œ"""
    # å®ç°æœç´¢é€»è¾‘
    return f"æœç´¢ç»“æœ: {query}"

def calculate(expression: str) -> str:
    """è®¡ç®—è¡¨è¾¾å¼"""
    return str(eval(expression))

tools = [
    Tool(name="Search", func=search_web, description="æœç´¢ç½‘ç»œä¿¡æ¯"),
    Tool(name="Calculator", func=calculate, description="è®¡ç®—æ•°å­¦è¡¨è¾¾å¼")
]

# åˆ›å»º Agent
llm = ChatOpenAI(model="gpt-4", temperature=0)
agent = create_react_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

# æ‰§è¡Œ
result = agent_executor.invoke({
    "input": "2024å¹´è¯ºè´å°”å¥–å¾—ä¸»æ˜¯è°ï¼Ÿç„¶åè®¡ç®—100é™¤ä»¥5"
})
```

### ä¸‰ã€ä½¿ç”¨ AutoGen å¼€å‘å¤š Agent ç³»ç»Ÿ

```python
# pip install pyautogen

import autogen

# é…ç½® LLM
config_list = [
    {
        "model": "gpt-4",
        "api_key": "your-api-key"
    }
]

# åˆ›å»º Agent
assistant = autogen.AssistantAgent(
    name="assistant",
    llm_config={"config_list": config_list}
)

user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    human_input_mode="NEVER",
    max_consecutive_auto_reply=10,
    code_execution_config={"work_dir": "coding"}
)

# å®šä¹‰ä»»åŠ¡
task = """
åˆ›å»ºä¸€ä¸ª Python è„šæœ¬ï¼Œå®ç°ä»¥ä¸‹åŠŸèƒ½ï¼š
1. ä» https://api.github.com/events è·å– GitHub äº‹ä»¶
2. è§£ææœ€è¿‘çš„ Push äº‹ä»¶
3. ä¿å­˜åˆ°æœ¬åœ° JSON æ–‡ä»¶
"""

# å¯åŠ¨å¯¹è¯
user_proxy.initiate_chat(assistant, message=task)
```

### å››ã€ä½¿ç”¨ CrewAI å¼€å‘å›¢é˜Ÿåä½œ Agent

```python
# pip install crewai

from crewai import Agent, Task, Crew, Process
from langchain_openai import ChatOpenAI

# åˆ›å»º Agent
researcher = Agent(
    role="ç ”ç©¶å‘˜",
    goal="æ”¶é›†å’Œåˆ†ææœ€æ–°çš„AIæŠ€æœ¯è¶‹åŠ¿",
    backstory="ä½ æ˜¯ä¸€ä½èµ„æ·±çš„AIç ”ç©¶å‘˜ï¼Œæ“…é•¿æŠ€æœ¯è¶‹åŠ¿åˆ†æ",
    verbose=True,
    allow_delegation=False,
    llm=ChatOpenAI(model="gpt-4", temperature=0.7)
)

writer = Agent(
    role="æŠ€æœ¯ä½œå®¶",
    goal="æ’°å†™æ¸…æ™°ã€æœ‰æ´å¯ŸåŠ›çš„æŠ€æœ¯æ–‡ç« ",
    backstory="ä½ æ˜¯ä¸€ä½æŠ€æœ¯å†™ä½œä¸“å®¶ï¼Œæ“…é•¿å°†å¤æ‚æ¦‚å¿µç®€å•åŒ–",
    verbose=True,
    allow_delegation=False,
    llm=ChatOpenAI(model="gpt-4", temperature=0.7)
)

# å®šä¹‰ä»»åŠ¡
research_task = Task(
    description="ç ”ç©¶2024å¹´æœ€é‡è¦çš„3ä¸ªAIçªç ´ï¼ŒåŒ…æ‹¬æŠ€æœ¯ç»†èŠ‚å’Œå½±å“",
    agent=researcher,
    expected_output="ä¸€ä»½è¯¦ç»†çš„ç ”ç©¶æŠ¥å‘Š"
)

writing_task = Task(
    description="åŸºäºç ”ç©¶æŠ¥å‘Šï¼Œæ’°å†™ä¸€ç¯‡é¢å‘æ™®é€šè¯»è€…çš„ç§‘æ™®æ–‡ç« ",
    agent=writer,
    expected_output="ä¸€ç¯‡1000å­—å·¦å³çš„ç§‘æ™®æ–‡ç« "
)

# åˆ›å»ºå›¢é˜Ÿ
crew = Crew(
    agents=[researcher, writer],
    tasks=[research_task, writing_task],
    process=Process.sequential,
    verbose=True
)

# æ‰§è¡Œä»»åŠ¡
result = crew.kickoff()
print(result)
```

### äº”ã€RAG + Agent å®æˆ˜

```python
from langchain import OpenAI, VectorDBQA
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import CharacterTextSplitter
from langchain.document_loaders import TextLoader
from langchain.agents import Tool, initialize_agent

# 1. åŠ è½½æ–‡æ¡£
loader = TextLoader("knowledge_base.txt")
documents = loader.load()

# 2. åˆ†å—
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)

# 3. åˆ›å»ºå‘é‡æ•°æ®åº“
embeddings = OpenAIEmbeddings()
vectordb = Chroma.from_documents(texts, embeddings)

# 4. åˆ›å»º RAG å·¥å…·
qa = VectorDBQA.from_chain_type(
    llm=OpenAI(),
    chain_type="stuff",
    vectorstore=vectordb
)

tools = [
    Tool(
        name="Knowledge Base",
        func=qa.run,
        description="ç”¨äºæŸ¥è¯¢çŸ¥è¯†åº“"
    )
]

# 5. åˆ›å»º Agent
agent = initialize_agent(
    tools,
    OpenAI(temperature=0),
    agent="zero-shot-react-description"
)

# 6. ä½¿ç”¨
response = agent.run("æ ¹æ®çŸ¥è¯†åº“ï¼Œä»€ä¹ˆæ˜¯æˆ‘ä»¬çš„é€€è´§æ”¿ç­–ï¼Ÿ")
```

---

## ğŸ“‹ å¿«é€Ÿä¸Šæ‰‹æ¸…å•

### Week 1: åŸºç¡€å…¥é—¨
- [ ] å®Œæˆ [Google ML Crash Course](https://developers.google.com/machine-learning/crash-course)
- [ ] å­¦ä¹  Python åŸºç¡€ (å¦‚æœè¿˜ä¸ç†Ÿæ‚‰)
- [ ] å®‰è£…å¹¶è¿è¡Œç¬¬ä¸€ä¸ª LLM (Ollama)

### Week 2: LLM åº”ç”¨å¼€å‘
- [ ] å­¦ä¹  LangChain åŸºç¡€
- [ ] å®Œæˆ [LangChain å®˜æ–¹æ•™ç¨‹](https://python.langchain.com/docs/get_started/quickstart)
- [ ] å¼€å‘ç¬¬ä¸€ä¸ª RAG åº”ç”¨

### Week 3: Agent å¼€å‘
- [ ] å­¦ä¹  ReAct æ¶æ„
- [ ] å¼€å‘å¸¦å·¥å…·çš„ Agent
- [ ] å®ç°è®°å¿†ç³»ç»Ÿ

### Week 4: æ¨¡å‹å®šåˆ¶
- [ ] å­¦ä¹  LoRA å¾®è°ƒ
- [ ] å‡†å¤‡æ•°æ®é›†
- [ ] å¾®è°ƒä¸€ä¸ªè‡ªå·±çš„æ¨¡å‹

---

## ğŸ”— æ¨èé¡¹ç›®ç»ƒæ‰‹

| é¡¹ç›® | éš¾åº¦ | æŠ€æœ¯æ ˆ | æè¿° |
|------|------|--------|------|
| **æ™ºèƒ½å®¢æœ** | â­â­ | RAG, LangChain | åŸºäºæ–‡æ¡£çš„é—®ç­”ç³»ç»Ÿ |
| **ä»£ç åŠ©æ‰‹** | â­â­â­ | Agent, Code Interpreter | è‡ªåŠ¨ç¼–ç¨‹åŠ©æ‰‹ |
| **ç ”æŠ¥ç”Ÿæˆå™¨** | â­â­â­ | Multi-Agent, CrewAI | è‡ªåŠ¨æ”¶é›†æ•°æ®å¹¶ç”ŸæˆæŠ¥å‘Š |
| **ä¸ªäººçŸ¥è¯†åº“** | â­â­ | RAG, Vector DB | ç®¡ç†ä¸ªäººç¬”è®°å’Œæ–‡æ¡£ |
| **è‡ªåŠ¨åŒ–å·¥ä½œæµ** | â­â­â­â­ | Agent, Tool Use | è‡ªåŠ¨æ‰§è¡Œå¤æ‚ä»»åŠ¡ |

---

## ğŸ’¡ å­¦ä¹ å»ºè®®

1. **åŠ¨æ‰‹ä¼˜å…ˆ**ï¼šä¸è¦åªçœ‹æ•™ç¨‹ï¼Œä¸€å®šè¦åŠ¨æ‰‹å†™ä»£ç 
2. **ä»ç®€å•å¼€å§‹**ï¼šå…ˆç”¨ç°æˆçš„APIå’Œæ¡†æ¶ï¼Œå†æ·±å…¥åº•å±‚
3. **å…³æ³¨ç¤¾åŒº**ï¼šå…³æ³¨ Hugging Face, LangChain, OpenAI çš„å®˜æ–¹è´¦å·
4. **é˜…è¯»æºç **ï¼šç†è§£ä¼˜ç§€é¡¹ç›®çš„å®ç°æ–¹å¼
5. **æŒç»­è¿­ä»£**ï¼šAI å‘å±•å¾ˆå¿«ï¼Œä¿æŒå­¦ä¹ 

---

*æœ€åæ›´æ–°ï¼š2026-02-16 | NewClaw Learning Hub*