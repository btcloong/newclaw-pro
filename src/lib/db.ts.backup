// 使用内存存储，适合 Vercel serverless 环境
// 数据在每次部署后重置，通过 API 触发重新抓取

import { AICategory, ArticleScores, AIProcessingResult } from "./ai-processor";

// 扩展的新闻项接口，包含 AI 处理字段
export interface NewsItem {
  id: string;
  title: string;
  summary: string;
  content?: string;
  url: string;
  source: string;
  sourceUrl?: string;
  image?: string;
  category: string;
  tags: string[];
  publishedAt: string;
  isHot?: boolean;
  isFeatured?: boolean;
  viewCount?: number;
  
  // AI 处理字段
  aiProcessed?: boolean;
  aiProcessingStatus?: "pending" | "processing" | "completed" | "failed";
  aiProcessedAt?: string;
  aiError?: string;
  
  // AI 评分
  aiScores?: ArticleScores;
  
  // AI 分类
  aiCategory?: AICategory;
  
  // AI 生成的内容
  chineseTitle?: string;
  aiSummary?: string;
  recommendation?: string;
  aiKeywords?: string[];
  
  // 前世今生背景信息
  background?: string;
  history?: string[];
  relatedNews?: string[];
}

export interface Project {
  id: string;
  name: string;
  description: string;
  fullDescription?: string;
  url: string;
  logo?: string;
  category: string;
  tags: string[];
  source: "github" | "producthunt" | "other";
  stars?: number;
  forks?: number;
  upvotes?: number;
  language?: string;
  license?: string;
  createdAt?: string;
  updatedAt?: string;
  isNew?: boolean;
  isTrending?: boolean;
}

export interface ResearchReport {
  id: string;
  title: string;
  summary: string;
  content?: string;
  category: string;
  tags: string[];
  author?: string;
  readTime?: string;
  publishedAt: string;
  viewCount?: number;
}

export interface HotTopic {
  id: string;
  title: string;
  heat: number;
  change: number;
  category?: string;
  rank: number;
}

export interface Funding {
  id: string;
  companyName: string;
  amount: string;
  round: string;
  date: string;
  investors: string[];
  category?: string;
  description?: string;
}

// Twitter 推文接口
export interface Tweet {
  id: string;
  content: string;
  author: {
    name: string;
    username: string;
    avatar?: string;
    verified?: boolean;
  };
  publishedAt: string;
  likes: number;
  retweets: number;
  replies: number;
  views?: number;
  media?: string[];
  hashtags: string[];
  mentions: string[];
  urls: string[];
  isHot?: boolean;
  sentiment?: "positive" | "neutral" | "negative";
  // AI 解读字段
  aiAnalysis?: {
    chineseSummary: string;
    keyPoints: string[];
    importance: "high" | "medium" | "low";
    category: string;
  };
}

// Twitter 话题趋势
export interface TwitterTrend {
  id: string;
  name: string;
  query: string;
  tweetVolume: number;
  rank: number;
  category?: string;
}

// 趋势总结接口
export interface DailyTrendSummary {
  date: string;
  summary: string;
  keyTrends: string[];
  notableArticles: string[];
  categoryDistribution: Record<string, number>;
  topKeywords: Array<{ keyword: string; count: number }>;
  generatedAt: string;
}

// 内存存储
let newsStore: NewsItem[] = [];
let projectsStore: Project[] = [];
let researchStore: ResearchReport[] = [];
let hotTopicsStore: HotTopic[] = [];
let fundingStore: Funding[] = [];
export let tweetsStore: Tweet[] = [];
export let twitterTrendsStore: TwitterTrend[] = [];
let trendSummaryStore: DailyTrendSummary | null = null;
let lastCrawlTime: string | null = null;
let lastAIProcessingTime: string | null = null;

// 生成2026年2月的真实AI新闻数据
function initSampleData() {
  const now = new Date();
  
  // 新闻数据 - 2026年2月最新AI行业动态 (20条)
  newsStore = [
    {
      id: "1",
      title: "OpenAI GPT-5 Preview Leaked: Multimodal Reasoning Breakthrough",
      summary: "OpenAI GPT-5预览版泄露，展示多模态推理能力的重大突破，在复杂逻辑任务上超越前代模型40%以上。",
      content: "据内部消息，OpenAI即将发布的GPT-5在内部测试中展现出惊人的多模态推理能力。新模型不仅能处理文本、图像和音频，还能在复杂逻辑推理任务上实现重大突破。消息人士透露，GPT-5在数学推理、代码生成和科学问题解答方面的准确率比GPT-4o提升了40%以上。",
      url: "https://openai.com/blog/gpt-5-preview",
      source: "OpenAI 官方博客",
      sourceUrl: "https://openai.com/blog/gpt-5-preview",
      image: "https://images.unsplash.com/photo-1677442136019-21780ecad995?w=800",
      category: "大模型",
      tags: ["OpenAI", "GPT-5", "多模态", "推理模型"],
      publishedAt: new Date(now.getTime() - 1000 * 60 * 30).toISOString(),
      isHot: true,
      isFeatured: true,
      viewCount: 285000,
      aiProcessed: true,
      aiProcessingStatus: "completed",
      aiProcessedAt: new Date().toISOString(),
      aiScores: {
        relevance: 10,
        quality: 9,
        timeliness: 10,
        overall: 9.7,
      },
      aiCategory: "AI/ML",
      chineseTitle: "OpenAI GPT-5预览泄露：多模态推理能力重大突破",
      aiSummary: "OpenAI GPT-5预览版展示多模态推理能力重大突破，在数学推理、代码生成和科学问题解答方面准确率比GPT-4o提升40%以上。这标志着大语言模型进入新阶段。",
      recommendation: "这是2026年最受期待的AI发布，多模态推理突破将改变AI应用场景。",
      aiKeywords: ["OpenAI", "GPT-5", "多模态", "推理突破"],
      background: "GPT系列是OpenAI的旗舰产品，从2018年的GPT-1发展到2024年的GPT-4o，每一代都带来显著性能提升。GPT-5的开发始于2024年中，历时18个月。",
      history: [
        "2024年5月：GPT-4o发布，首次实现原生多模态",
        "2024年12月：o3推理模型发布，展示强大推理能力",
        "2025年6月：GPT-5开始内部测试",
        "2026年1月：预览版向部分开发者开放",
        "2026年2月：即将正式发布"
      ],
      relatedNews: ["2", "5", "11"]
    },
    {
      id: "2",
      title: "DeepSeek R2 Officially Released: 40% Cost Reduction with Superior Performance",
      summary: "DeepSeek正式发布R2模型，在保持高性能的同时将推理成本降低40%，挑战OpenAI和Google的市场地位。",
      content: "中国AI公司DeepSeek于2026年2月10日正式发布DeepSeek-R2模型。新模型采用创新的稀疏专家混合架构（Sparse MoE），在保持与GPT-4o相当性能的同时，将推理成本降低了40%。DeepSeek-R2支持128K上下文窗口，在多语言理解和代码生成方面表现尤为出色。",
      url: "https://www.deepseek.com/blog/r2-release",
      source: "DeepSeek 官方",
      sourceUrl: "https://www.deepseek.com/blog/r2-release",
      image: "https://images.unsplash.com/photo-1620712943543-bcc4688e7485?w=800",
      category: "开源模型",
      tags: ["DeepSeek", "R2", "开源模型", "MoE", "中国AI"],
      publishedAt: new Date(now.getTime() - 1000 * 60 * 60 * 2).toISOString(),
      isHot: true,
      viewCount: 356000,
      aiProcessed: true,
      aiProcessingStatus: "completed",
      aiProcessedAt: new Date().toISOString(),
      aiScores: {
        relevance: 10,
        quality: 9,
        timeliness: 10,
        overall: 9.7,
      },
      aiCategory: "AI/ML",
      chineseTitle: "DeepSeek R2正式发布：成本降低40%性能更优",
      aiSummary: "DeepSeek R2采用创新稀疏MoE架构，在保持GPT-4o级别性能的同时将推理成本降低40%，支持128K上下文窗口，在多语言和代码生成方面表现出色。",
      recommendation: "中国AI模型的又一重大突破，高性价比选择值得开发者关注。",
      aiKeywords: ["DeepSeek", "R2", "MoE", "成本优化"],
      background: "DeepSeek成立于2023年，是中国量化私募幻方量化旗下的AI公司。2024年12月发布的V3模型以557万美元训练成本引发全球关注。",
      history: [
        "2023年：DeepSeek成立",
        "2024年5月：DeepSeek-V2发布，首次展示MoE架构优势",
        "2024年12月：DeepSeek-V3发布，低成本高性能引发轰动",
        "2025年8月：R1推理模型发布",
        "2026年2月：R2正式发布，成本效率再突破"
      ],
      relatedNews: ["1", "3", "12"]
    },
    {
      id: "3",
      title: "Google Gemini 2.5 Pro Unveiled: Native Multimodal with 2M Context",
      summary: "Google发布Gemini 2.5 Pro，支持200万token上下文窗口，原生多模态能力全面升级，可直接处理视频和音频。",
      content: "Google DeepMind于2026年2月8日发布Gemini 2.5 Pro模型。新模型支持惊人的200万token上下文窗口，可以一次性处理整本书籍或数小时视频内容。Gemini 2.5 Pro实现了真正的原生多模态，能够无缝理解文本、图像、音频和视频，并在不同模态之间进行推理。",
      url: "https://blog.google/technology/ai/gemini-2-5-pro/",
      source: "Google Blog",
      sourceUrl: "https://blog.google/technology/ai/gemini-2-5-pro/",
      image: "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800",
      category: "大模型",
      tags: ["Google", "Gemini", "多模态", "长上下文"],
      publishedAt: new Date(now.getTime() - 1000 * 60 * 60 * 4).toISOString(),
      isHot: true,
      viewCount: 289000,
      aiProcessed: true,
      aiProcessingStatus: "completed",
      aiProcessedAt: new Date().toISOString(),
      aiScores: {
        relevance: 9,
        quality: 9,
        timeliness: 9,
        overall: 9.0,
      },
      aiCategory: "AI/ML",
      chineseTitle: "Google Gemini 2.5 Pro发布：200万上下文原生多模态",
      aiSummary: "Google Gemini 2.5 Pro支持200万token超长上下文，实现真正的原生多模态理解，可无缝处理文本、图像、音频和视频，在多模态AI领域保持领先。",
      recommendation: "超长上下文和多模态能力的结合，为复杂应用场景提供新可能。",
      aiKeywords: ["Google", "Gemini", "多模态", "长上下文"],
      background: "Gemini是Google DeepMind开发的大语言模型系列，2023年12月首次发布。Gemini从一开始就设计为多模态模型，与GPT系列形成差异化竞争。",
      history: [
        "2023年12月：Gemini 1.0发布",
        "2024年2月：Gemini 1.5发布，引入100万上下文",
        "2024年12月：Gemini 2.0 Flash发布",
        "2025年6月：Gemini 2.0 Pro发布",
        "2026年2月：Gemini 2.5 Pro发布，上下文扩展至200万"
      ],
      relatedNews: ["1", "2", "15"]
    },
    {
      id: "4",
      title: "xAI Grok 3.5 Released: Real-time Web Search with Deep Reasoning",
      summary: "马斯克xAI发布Grok 3.5，整合实时网络搜索与深度推理能力，在信息准确性和时效性上实现突破。",
      content: "xAI于2026年2月12日发布Grok 3.5模型。新版本整合了实时网络搜索能力与深度推理功能，可以实时获取最新信息并进行深度分析。Grok 3.5在X平台上实时训练，对社交媒体动态和新闻事件的理解能力显著提升。马斯克称这是'最懂互联网的AI'。",
      url: "https://x.ai/blog/grok-3-5",
      source: "xAI 官方博客",
      sourceUrl: "https://x.ai/blog/grok-3-5",
      image: "https://images.unsplash.com/photo-1518709268805-4e9042af9f23?w=800",
      category: "大模型",
      tags: ["xAI", "Grok", "马斯克", "实时搜索"],
      publishedAt: new Date(now.getTime() - 1000 * 60 * 60 * 6).toISOString(),
      isHot: true,
      viewCount: 267000,
      aiProcessed: true,
      aiProcessingStatus: "completed",
      aiProcessedAt: new Date().toISOString(),
      aiScores: {
        relevance: 9,
        quality: 8,
        timeliness: 10,
        overall: 8.9,
      },
      aiCategory: "AI/ML",
      chineseTitle: "xAI Grok 3.5发布：实时搜索与深度推理结合",
      aiSummary: "xAI Grok 3.5整合实时网络搜索与深度推理，在X平台实时训练，对社交媒体和新闻事件理解能力显著提升，信息时效性达到新高度。",
      recommendation: "需要实时信息的应用场景首选，社交媒体动态理解能力突出。",
      aiKeywords: ["xAI", "Grok", "实时搜索", "X平台"],
      background: "xAI由埃隆·马斯克于2023年创立，旨在'理解宇宙的本质'。Grok系列模型以幽默、叛逆的风格和实时信息获取能力著称。",
      history: [
        "2023年7月：xAI成立",
        "2023年11月：Grok-1发布，仅限X Premium用户",
        "2024年3月：Grok-1.5发布，上下文扩展",
        "2025年2月：Grok 3发布，宣称'最聪明AI'",
        "2026年2月：Grok 3.5发布，实时搜索能力增强"
      ],
      relatedNews: ["1", "5", "16"]
    },
    {
      id: "5",
      title: "Meta Llama 4 Preview: Open Source Model Nears GPT-5 Performance",
      summary: "Meta预览Llama 4，开源模型性能接近GPT-5水平，4000亿参数MoE架构引发开源社区轰动。",
      content: "Meta于2026年2月14日向研究人员预览Llama 4模型。这款4000亿参数的开源模型采用MoE架构，在多项基准测试中接近GPT-5的性能水平。Llama 4支持多语言和代码生成，Meta承诺将完全开源模型权重，引发开源AI社区的热烈反响。",
      url: "https://ai.meta.com/blog/llama-4-preview/",
      source: "Meta AI Blog",
      sourceUrl: "https://ai.meta.com/blog/llama-4-preview/",
      image: "https://images.unsplash.com/photo-1611162617474-5b21e879e113?w=800",
      category: "开源模型",
      tags: ["Meta", "Llama", "开源", "大模型"],
      publishedAt: new Date(now.getTime() - 1000 * 60 * 60 * 8).toISOString(),
      viewCount: 234000,
      aiProcessed: true,
      aiProcessingStatus: "completed",
      aiProcessedAt: new Date().toISOString(),
      aiScores: {
        relevance: 9,
        quality: 8,
        timeliness: 9,
        overall: 8.6,
      },
      aiCategory: "开源",
      chineseTitle: "Meta Llama 4预览：开源模型逼近GPT-5性能",
      aiSummary: "Meta Llama 4采用4000亿参数MoE架构，在多项基准测试中接近GPT-5水平，Meta承诺完全开源，对开源AI生态具有里程碑意义。",
      recommendation: "开源模型爱好者的福音，4000亿参数MoE架构值得深入研究。",
      aiKeywords: ["Meta", "Llama", "开源", "MoE"],
      background: "Llama系列是Meta推出的开源大语言模型，2023年2月首次发布Llama 1。Llama的开源策略打破了OpenAI和Google的闭源垄断，推动了开源AI的发展。",
      history: [
        "2023年2月：Llama 1发布，仅限研究用途",
        "2023年7月：Llama 2发布，允许商业使用",
        "2024年4月：Llama 3发布，性能大幅提升",
        "2024年12月：Llama 3.3发布，70B参数达到405B性能",
        "2026年2月：Llama 4预览，开源模型新高度"
      ],
      relatedNews: ["2", "6", "12"]
    },
    {
      id: "6",
      title: "Anthropic Claude 4 Opus: Safety-First AI with 500K Context",
      summary: "Anthropic发布Claude 4 Opus，强调AI安全与对齐，50万上下文窗口，在医疗和法律领域表现卓越。",
      content: "Anthropic于2026年2月5日发布Claude 4 Opus模型。新模型延续Anthropic对AI安全的重视，采用Constitutional AI 2.0技术，在保持强大能力的同时大幅降低有害输出。Claude 4 Opus支持50万token上下文，在医疗诊断辅助和法律文档分析等专业领域表现卓越。",
      url: "https://www.anthropic.com/news/claude-4-opus",
      source: "Anthropic 官方",
      sourceUrl: "https://www.anthropic.com/news/claude-4-opus",
      image: "https://images.unsplash.com/photo-1555949963-aa79dcee981c?w=800",
      category: "大模型",
      tags: ["Anthropic", "Claude", "AI安全", "长上下文"],
      publishedAt: new Date(now.getTime() - 1000 * 60 * 60 * 12).toISOString(),
      isHot: true,
      viewCount: 198000,
      aiProcessed: true,
      aiProcessingStatus: "completed",
      aiProcessedAt: new Date().toISOString(),
      aiScores: {
        relevance: 9,
        quality: 9,
        timeliness: 8,
        overall: 8.6,
      },
      aiCategory: "AI/ML",
      chineseTitle: "Anthropic Claude 4 Opus：安全优先的50万上下文AI",
      aiSummary: "Claude 4 Opus采用Constitutional AI 2.0技术，在医疗和法律等专业领域表现卓越，延续Anthropic对AI安全和负责任开发的承诺。",
      recommendation: "对AI安全性要求高的企业应用场景首选，专业领域表现出色。",
      aiKeywords: ["Anthropic", "Claude", "AI安全", "专业应用"],
      background: "Anthropic由OpenAI前研究副总裁Dario Amodei于2021年创立，专注于AI安全研究。Constitutional AI是Anthropic开发的对齐技术，通过原则约束模型行为。",
      history: [
        "2021年：Anthropic成立",
        "2023年3月：Claude 1.0发布",
        "2023年7月：Claude 2发布",
        "2024年3月：Claude 3系列发布",
        "2024年6月：Claude 3.5 Sonnet发布",
        "2026年2月：Claude 4 Opus发布"
      ],
      relatedNews: ["5", "13", "17"]
    },
    {
      id: "7",
      title: "AI Agent Revolution: AutoGPT 2.0 Achieves 90% Task Completion",
      summary: "AutoGPT 2.0发布，AI智能体任务完成率达90%，可自主执行复杂多步骤工作流，商业化应用加速落地。",
      content: "AutoGPT团队于2026年2月11日发布2.0版本，标志着AI智能体技术的重大突破。新版本采用改进的规划和执行架构，在复杂任务上的自主完成率达到90%。AutoGPT 2.0支持多智能体协作、工具调用和长期记忆，已开始在客户服务、数据分析和内容创作等领域商业化应用。",
      url: "https://autogpt.net/autogpt-2-0-release/",
      source: "AutoGPT 官方",
      sourceUrl: "https://autogpt.net/autogpt-2-0-release/",
      image: "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800",
      category: "AI Agent",
      tags: ["AutoGPT", "AI Agent", "智能体", "自动化"],
      publishedAt: new Date(now.getTime() - 1000 * 60 * 60 * 10).toISOString(),
      isHot: true,
      viewCount: 312000,
      aiProcessed: true,
      aiProcessingStatus: "completed",
      aiProcessedAt: new Date().toISOString(),
      aiScores: {
        relevance: 10,
        quality: 8,
        timeliness: 9,
        overall: 9.0,
      },
      aiCategory: "应用",
      chineseTitle: "AI智能体革命：AutoGPT 2.0任务完成率达90%",
      aiSummary: "AutoGPT 2.0采用改进的规划和执行架构，复杂任务自主完成率达90%，支持多智能体协作和长期记忆，商业化应用加速落地。",
      recommendation: "AI Agent领域的里程碑进展，自动化工作流程的重要突破。",
      aiKeywords: ["AutoGPT", "AI Agent", "智能体", "自动化"],
      background: "AutoGPT于2023年3月发布，是首个开源的自主AI智能体项目，能够根据目标自主分解任务并执行。它引发了AI Agent技术的热潮。",
      history: [
        "2023年3月：AutoGPT发布，引发AI Agent热潮",
        "2023年8月：0.5版本发布，稳定性提升",
        "2024年4月：1.0版本发布，架构重构",
        "2025年6月：引入多智能体协作功能",
        "2026年2月：2.0版本发布，任务完成率突破90%"
      ],
      relatedNews: ["8", "14", "18"]
    },
    {
      id: "8",
      title: "Microsoft Copilot Studio: Build Custom AI Agents Without Code",
      summary: "微软发布Copilot Studio，无代码平台让普通用户也能创建自定义AI智能体，集成Office 365生态。",
      content: "微软于2026年2月9日发布Copilot Studio平台，让非技术用户也能通过可视化界面创建自定义AI智能体。平台深度集成Office 365、Teams和Power Platform，支持自然语言定义工作流、自动连接企业数据源。微软表示已有超过10万家企业参与测试。",
      url: "https://www.microsoft.com/en-us/microsoft-copilot/blog/",
      source: "Microsoft 官方",
      sourceUrl: "https://www.microsoft.com/en-us/microsoft-copilot/blog/",
      image: "https://images.unsplash.com/photo-1633419461186-7d40a38105ec?w=800",
      category: "AI Agent",
      tags: ["Microsoft", "Copilot", "无代码", "企业应用"],
      publishedAt: new Date(now.getTime() - 1000 * 60 * 60 * 14).toISOString(),
      viewCount: 245000,
      aiProcessed: true,
      aiProcessingStatus: "completed",
      aiProcessedAt: new Date().toISOString(),
      aiScores: {
        relevance: 9,
        quality: 8,
        timeliness: 8,
        overall: 8.3,
      },
      aiCategory: "应用",
      chineseTitle: "微软Copilot Studio：无代码创建AI智能体",
      aiSummary: "微软Copilot Studio让非技术用户通过可视化界面创建自定义AI智能体，深度集成Office 365生态，已有超10万家企业参与测试。",
      recommendation: "企业数字化转型的利器，无代码平台大幅降低AI应用门槛。",
      aiKeywords: ["Microsoft", "Copilot", "无代码", "企业AI"],
      background: "微软于2023年推出Copilot品牌，将AI助手集成到Windows、Office和Edge等产品中。Copilot Studio是微软企业AI战略的重要组成部分。",
      history: [
        "2023年3月：Microsoft 365 Copilot发布",
        "2023年9月：Copilot集成Windows 11",
        "2024年5月：Copilot Studio预览版发布",
        "2025年3月：Copilot for Security发布",
        "2026年2月：Copilot Studio正式版发布"
      ],
      relatedNews: ["7", "19", "20"]
    },
    {
      id: "9",
      title: "NVIDIA Blackwell Ultra: 2x Performance for AI Training",
      summary: "NVIDIA发布Blackwell Ultra GPU，AI训练性能提升2倍，能效比提高40%，进一步巩固AI芯片霸主地位。",
      content: "NVIDIA于2026年2月13日发布Blackwell Ultra GPU，基于改进的4nm工艺。新芯片在AI训练任务上性能比前代提升2倍，能效比提高40%。Blackwell Ultra支持FP4和FP8精度计算，专为大规模语言模型训练优化。主要云服务商已宣布支持。",
      url: "https://nvidia.com/en-us/data-center/blackwell-ultra/",
      source: "NVIDIA 官方",
      sourceUrl: "https://nvidia.com/en-us/data-center/blackwell-ultra/",
      image: "https://images.unsplash.com/photo-1555664424-778a69022365?w=800",
      category: "AI芯片",
      tags: ["NVIDIA", "Blackwell", "GPU", "AI芯片"],
      publishedAt: new Date(now.getTime() - 1000 * 60 * 60 * 16).toISOString(),
      isHot: true,
      viewCount: 278000,
      aiProcessed: true,
      aiProcessingStatus: "completed",
      aiProcessedAt: new Date().toISOString(),
      aiScores: {
        relevance: 9,
        quality: 8,
        timeliness: 9,
        overall: 8.6,
      },
      aiCategory: "硬件",
      chineseTitle: "NVIDIA Blackwell Ultra：AI训练性能翻倍",
      aiSummary: "NVIDIA Blackwell Ultra基于改进4nm工艺，AI训练性能提升2倍，能效比提高40%，支持FP4/FP8精度，专为大规模模型训练优化。",
      recommendation: "AI基础设施的核心组件，训练效率提升将降低模型开发成本。",
      aiKeywords: ["NVIDIA", "Blackwell", "GPU", "AI训练"],
      background: "NVIDIA是全球AI芯片领导者，其GPU被广泛用于深度学习训练和推理。Blackwell架构于2024年3月首次发布，是Hopper架构的继任者。",
      history: [
        "2022年3月：Hopper架构发布",
        "2024年3月：Blackwell架构首次发布",
        "2024年8月：Blackwell GPU开始出货",
        "2025年6月：Blackwell B200发布",
        "2026年2月：Blackwell Ultra发布，性能大幅提升"
      ],
      relatedNews: ["10", "21", "22"]
    },
    {
      id: "10",
      title: "Apple M4 Ultra Chip: On-Device AI with 50B Parameters",
      summary: "苹果发布M4 Ultra芯片，支持本地运行500亿参数模型，Mac AI能力迎来质的飞跃。",
      content: "苹果于2026年2月7日发布M4 Ultra芯片，集成192GB统一内存和800GB/s内存带宽。新芯片的神经网络引擎性能比M3 Ultra提升3倍，支持本地运行500亿参数大模型。苹果同时发布Apple Intelligence 2.0，将更多AI功能带到Mac、iPhone和iPad。",
      url: "https://www.apple.com/newsroom/2026/02/apple-unveils-m4-ultra/",
      source: "Apple 官方",
      sourceUrl: "https://www.apple.com/newsroom/2026/02/apple-unveils-m4-ultra/",
      image: "https://images.unsplash.com/photo-1517336714731-489689fd1ca8?w=800",
      category: "AI芯片",
      tags: ["Apple", "M4 Ultra", "端侧AI", "神经引擎"],
      publishedAt: new Date(now.getTime() - 1000 * 60 * 60 * 18).toISOString(),
      viewCount: 223000,
      aiProcessed: true,
      aiProcessingStatus: "completed",
      aiProcessedAt: new Date().toISOString(),
      aiScores: {
        relevance: 8,
        quality: 8,
        timeliness: 8,
        overall: 8.0,
      },
      aiCategory: "硬件",
      chineseTitle: "苹果M4 Ultra芯片：本地运行500亿参数模型",
      aiSummary: "苹果M4 Ultra集成192GB统一内存，神经网络引擎性能提升3倍，支持本地运行500亿参数模型，端侧AI能力迎来质的飞跃。",
      recommendation: "端侧AI的重要里程碑，隐私保护和离线AI应用的理想选择。",
      aiKeywords: ["Apple", "M4 Ultra", "端侧AI", "本地推理"],
      background: "苹果自2020年推出M1芯片以来，持续推动自研芯片发展。Apple Intelligence于2024年WWDC发布，是苹果的端侧AI战略核心。",
      history: [
        "2020年11月：M1芯片发布，苹果 silicon 转型开始",
        "2023年6月：M2 Ultra发布",
        "2024年6月：Apple Intelligence发布",
        "2024年10月：M4系列发布",
        "2026年2月：M4 Ultra发布，端侧AI能力大幅提升"
      ],
      relatedNews: ["9", "23", "24"]
    },
    {
      id: "11",
      title: "OpenAI Sora Public Release: Text-to-Video Goes Mainstream",
      summary: "OpenAI正式发布Sora视频生成模型，支持1080p 60秒视频生成，向ChatGPT Plus用户开放。",
      content: "OpenAI于2026年2月6日正式向公众发布Sora视频生成模型。Sora支持根据文本描述生成最长60秒、1080p分辨率的视频，支持多种风格和镜头运动。该功能已向ChatGPT Plus和Pro订阅用户开放。OpenAI同时推出Sora API，供开发者集成。",
      url: "https://openai.com/sora",
      source: "OpenAI 官方",
      sourceUrl: "https://openai.com/sora",
      image: "https://images.unsplash.com/photo-1536240478700-b869070f9279?w=800",
      category: "视频生成",
      tags: ["OpenAI", "Sora", "视频生成", "AIGC"],
      publishedAt: new Date(now.getTime() - 1000 * 60 * 60 * 20).toISOString(),
      isHot: true,
      viewCount: 456000,
      aiProcessed: true,
      aiProcessingStatus: "completed",
      aiProcessedAt: new Date().toISOString(),
      aiScores: {
        relevance: 10,
        quality: 9,
        timeliness: 9,
        overall: 9.3,
      },
      aiCategory: "AIGC",
      chineseTitle: "OpenAI Sora正式发布：文本生成视频走向主流",
      aiSummary: "OpenAI Sora支持1080p 60秒视频生成，已向ChatGPT Plus用户开放，同时推出API供开发者集成，标志着AI视频生成进入主流应用阶段。",
      recommendation: "AI视频生成的里程碑，内容创作者和营销人员的强大工具。",
      aiKeywords: ["OpenAI", "Sora", "视频生成", "AIGC"],
      background: "Sora于2024年2月首次技术预览，展示了惊人的视频生成能力，但因安全考虑未立即开放。经过一年多的安全测试和改进，终于向公众发布。",
      history: [
        "2024年2月：Sora技术预览，展示惊艳效果",
